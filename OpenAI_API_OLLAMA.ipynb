{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a1dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e2a4632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models \n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51077e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the environment \n",
    "load_dotenv()\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32846b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your question:what is Langchain \n"
     ]
    }
   ],
   "source": [
    "#here is the question\n",
    "\n",
    "#question = \"\"\"\n",
    "#Please explain what this code does and why:\n",
    "#yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "#\"\"\"\n",
    "\n",
    "question = input(\"Please enter your question:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "029fe396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompts\n",
    "system_prompt = \"You are a helpful technical tutor who answers questions about python code, software engineering, data science and LLMs\"\n",
    "user_prompt = \"Please give a detailed explanation to the following question: \" + question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e8fa18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e7ad090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "LangChain is a framework designed to facilitate the development of applications using large language models (LLMs), like OpenAI's GPT models, in combination with other data sources and functionalities. It provides a structured way to integrate LLMs into various applications that require natural language understanding and generation alongside other data processing or retrieval capabilities.\n",
       "\n",
       "Here are some key aspects and components of LangChain:\n",
       "\n",
       "### 1. **Components of LangChain:**\n",
       "LangChain consists of several core components that enable developers to build robust applications with LLMs:\n",
       "\n",
       "- **Prompt Templates:** A way to structure the input (prompts) given to language models. This helps in standardizing how queries are formatted, which can enhance the consistency and reliability of responses.\n",
       "\n",
       "- **Chains:** These represent a sequence of calls that may involve multiple steps or transformations. For instance, this could mean taking user input, processing it through the LLM, and then using additional operations like summarization or data retrieval.\n",
       "\n",
       "- **Agents:** Agents are more dynamic components that can decide how to interact with various tools or data sources based on user input. For instance, an agent could discern whether to simply generate text or to pull in data from an external database before responding.\n",
       "\n",
       "- **Memory:** LangChain supports memory components that allow interactions to be contextual. This means an application can remember previous interactions with a user to provide contextually relevant responses in ongoing conversations.\n",
       "\n",
       "### 2. **Integrations:**\n",
       "LangChain is designed to work with various LLMs and can integrate with numerous data sources and APIs, enabling developers to build complex applications easily. This could include:\n",
       "\n",
       "- Connecting LLMs with APIs to gather real-time data.\n",
       "- Interfacing with databases for structured information retrieval.\n",
       "- Using other AI or machine learning models alongside LLMs.\n",
       "\n",
       "### 3. **Use Cases:**\n",
       "LangChain can be applied in various domains, such as:\n",
       "\n",
       "- **Chatbots and Conversational Agents:** Creating intelligent chat experiences that can remember user preferences and context over time.\n",
       "  \n",
       "- **Data Analysis and Insights:** Automatically generating reports or summaries by pulling data from different sources and presenting it in a human-readable format.\n",
       "\n",
       "- **Content Creation Tools:** Empowering applications that help users draft emails, articles, or other written content with AI assistance.\n",
       "\n",
       "- **Question-Answering Systems:** Building robust QA systems that not only respond with generated text but also retrieve and incorporate factual information from data stores.\n",
       "\n",
       "### 4. **Flexibility and Customization:**\n",
       "One of LangChain's strengths is its flexibility. Developers can create customized workflows that combine various components based on specific application needs. This allows users to optimize the interaction between the language model outputs and other data-handling components.\n",
       "\n",
       "### 5. **Community and Ecosystem:**\n",
       "LangChain has gained traction within the AI development community, leading to a growing ecosystem of tools, integrations, and shared knowledge. Documentation, tutorials, and practical examples are often available, making it easier to adopt and implement.\n",
       "\n",
       "### Conclusion:\n",
       "LangChain represents a significant advancement in making LLMs more usable and effective in practical applications. By providing a cohesive framework that integrates with various tools and data sources, it empowers developers to create sophisticated AI-driven applications that can understand and generate human-like text in a contextual manner. Whether for chatbots, data-driven insights, or creative writing, LangChain helps streamline the development process and enhances the capabilities of language models in diverse scenarios."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "stream = openai.chat.completions.create(model=MODEL_GPT,\n",
    "                                        messages=messages,\n",
    "                                        stream=True)\n",
    "\n",
    "response =\"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e39d66fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**LangChain: A Unified Platform for Natural Language Processing (NLP) and Knowledge Graphs**\n",
       "\n",
       "LangChain is an open-source Python library that aims to provide a unified platform for building natural language processing (NLP) and knowledge graph-based applications. It was designed by researchers at MIT and is based on the popular Transformers library from Hugging Face.\n",
       "\n",
       "**Key Features of LangChain**\n",
       "\n",
       "1. **Unified API**: LangChain provides a single, unified API that allows developers to easily integrate various NLP models and knowledge graphs into their applications.\n",
       "2. **Transformers Integration**: LangChain supports the use of Transformers-based models for a wide range of NLP tasks, including text classification, sentiment analysis, and language translation.\n",
       "3. **Knowledge Graph Embeddings**: LangChain provides support for knowledge graph embeddings, which enable the representation of complex relationships between entities in a knowledge graph.\n",
       "4. **Graph Neural Networks (GNNs)**: LangChain includes GNN-based modules that can be used to build more complex models, such as those that take into account both text and knowledge graph inputs.\n",
       "\n",
       "**Components of LangChain**\n",
       "\n",
       "LangChain consists of several key components:\n",
       "\n",
       "1. **Pipeline**: The pipeline is the core component of LangChain, which allows developers to define a sequence of tasks to perform on input data.\n",
       "2. **Task**: Tasks represent individual NLP or knowledge graph-based operations that can be performed on input data.\n",
       "3. **Module**: Modules are reusable pieces of code that can be used to build more complex models. They provide pre-built functionality for common NLP and knowledge graph-based tasks.\n",
       "4. **Graph**: The graph represents the structure of the knowledge graph, including entities, relationships, and nodes.\n",
       "\n",
       "**Use Cases for LangChain**\n",
       "\n",
       "LangChain is designed to support a wide range of use cases, including:\n",
       "\n",
       "1. **Question Answering (QA)**: LangChain can be used to build QA systems that take into account both text-based input and knowledge graph-based information.\n",
       "2. **Text Summarization**: LangChain can be used to build text summarization models that incorporate both text-based and knowledge graph-based inputs.\n",
       "3. **Information Retrieval**: LangChain can be used to build information retrieval systems that take into account both text-based and knowledge graph-based queries.\n",
       "\n",
       "**Example Use Case: Building a QA System with LangChain**\n",
       "\n",
       "Here's an example of how you might use LangChain to build a simple QA system:\n",
       "```python\n",
       "import langchain\n",
       "\n",
       "# Define the pipeline for our QA system\n",
       "pipeline = langchain.Pipeline(\n",
       "    tasks=[\n",
       "        langchain.Task(\"Text Classification\", model=langchain.models.TextClassifier()),\n",
       "        langchain.Task(\"Knowledge Graph Embeddings\", model=langchain.models.KGEmbedder())\n",
       "    ]\n",
       ")\n",
       "\n",
       "# Create an instance of our QA system\n",
       "qa_system = pipeline()\n",
       "\n",
       "# Define a sample question and text input\n",
       "question = \"What is the capital of France?\"\n",
       "text_input = \"The capital of France is Paris.\"\n",
       "\n",
       "# Use our QA system to answer the question\n",
       "answer = qa_system(question, text_input)\n",
       "print(answer)\n",
       "```\n",
       "This code defines a simple QA system using LangChain's unified API, which takes into account both text-based input and knowledge graph-based information.\n",
       "\n",
       "In conclusion, LangChain is an exciting new library that aims to provide a unified platform for building NLP and knowledge graph-based applications. Its components, such as the pipeline, task, module, and graph, provide a flexible and modular framework for developers to build more complex models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get LLama 3.2 to answer\n",
    "response = ollama.chat(model=MODEL_LLAMA,\n",
    "                      messages=messages)\n",
    "reply = response['message']['content']\n",
    "display(Markdown(reply))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
